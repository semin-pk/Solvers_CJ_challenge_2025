import pandas as pd
import numpy as np
from dataclasses import dataclass
from typing import Dict, List, Set
from collections import defaultdict
from itertools import combinations
from sklearn.cluster import SpectralClustering

# FIFOë¡œ ì²˜ë¦¬í•˜ëŠ” ìƒ˜í”Œ ì•Œê³ ë¦¬ì¦˜ ì…ë‹ˆë‹¤.
# def mainì²˜ëŸ¼ ë°ì´í„°í”„ë ˆì„ íƒ€ì…ìœ¼ë¡œ ê²°ê³¼ ë¦¬í„´í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤. ë°ì´í„°ëŠ” ì œê³µí•œ Sample_OutputData.csvì™€ ë™ì¼í•œ í˜•íƒœë¡œ ë¦¬í„´í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.

@dataclass
class WarehouseParameters:
    picking_time: float
    walking_time: float
    cart_capacity: int
    rack_capacity: int
    number_pickers: int

class WarehouseSolver:
    def __init__(self, orders: pd.DataFrame, parameters: pd.DataFrame, od_matrix: pd.DataFrame):
        self.orders = orders.copy()
        self.params = self._load_parameters(parameters)
        self.od_matrix = od_matrix
        self.start_location = od_matrix.index[0]
        self.end_location = od_matrix.index[1]
        
        self._initialize_orders()
        self._validate_input()

        self.cooc = None
        self.zone_cooc = None, 
        self.ordered_zone = None
        self.rack_to_zone = None
    def _load_parameters(self, parameters: pd.DataFrame) -> WarehouseParameters:
        get_param = lambda x: parameters.loc[parameters['PARAMETERS'] == x, 'VALUE'].iloc[0]
        return WarehouseParameters(
            picking_time=float(get_param('PT')),
            walking_time=float(get_param('WT')),
            cart_capacity=int(get_param('CAPA')),
            rack_capacity=int(get_param('RK')),
            number_pickers=int(get_param('PK'))
        )

    def _initialize_orders(self) -> None:
        self.orders['LOC'] = pd.NA
        self.orders['LOC'] = self.orders['LOC'].astype(str)
        self.orders['CART_NO'] = pd.NA
        self.orders['SEQ'] = pd.NA

    def _validate_input(self) -> None:
        if self.orders.empty or self.od_matrix.empty:
            raise ValueError("Input data or OD matrix is empty")
        required_columns = {'ORD_NO', 'SKU_CD'}
        if not required_columns.issubset(self.orders.columns):
            raise ValueError(f"Missing required columns: {required_columns - set(self.orders.columns)}")

#SKU í´ëŸ¬ìŠ¤í„°ë§ Nê°’ ì—˜ë³´ìš° ê¸°ë²• ì ìš©
    '''def solve_storage_location(self) -> None:
        import networkx as nx
        from sklearn.cluster import SpectralClustering
        from sklearn.metrics import silhouette_score
        import numpy as np
        from collections import defaultdict
        from itertools import combinations

        # 1ï¸âƒ£ SKU ë¹ˆë„
        freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2ï¸âƒ£ SKU ê°„ ê³µì¶œí˜„ (Jaccard)
        order_dict = defaultdict(set)
        for ord_no, sku in self.orders[['ORD_NO', 'SKU_CD']].values:
            order_dict[sku].add(ord_no)

        self.cooc = {}
        for a, b in combinations(skus_by_freq, 2):
            inter = len(order_dict[a] & order_dict[b])
            union = len(order_dict[a] | order_dict[b])
            if union > 0:
                jaccard = inter / union
                self.cooc[(a, b)] = jaccard
                self.cooc[(b, a)] = jaccard

        # 3ï¸âƒ£ SKU ìœ ì‚¬ë„ í–‰ë ¬
        S_sku = np.zeros((len(skus_by_freq), len(skus_by_freq)))
        for i, a in enumerate(skus_by_freq):
            for j, b in enumerate(skus_by_freq):
                S_sku[i, j] = self.cooc.get((a, b), 0)

        # 4ï¸âƒ£ ì—˜ë³´ìš° ê¸°ë²•ìœ¼ë¡œ ìµœì  í´ëŸ¬ìŠ¤í„° ìˆ˜
        max_k = len(skus_by_freq) // self.params.rack_capacity
        if max_k < 2:
            max_k = 2
        max_k = min(max_k, 10)

        best_k, best_score = 2, -1
        for k in range(2, max_k+1):
            clustering = SpectralClustering(
                n_clusters=k,
                affinity='precomputed',
                assign_labels='discretize',
                random_state=0
            )
            labels = clustering.fit_predict(S_sku)
            try:
                score = silhouette_score(S_sku, labels, metric='precomputed')
            except Exception:
                score = -1
            if score > best_score:
                best_k = k
                best_score = score

        n_clusters = best_k

        # 5ï¸âƒ£ ìµœì  kë¡œ í´ëŸ¬ìŠ¤í„°ë§
        clustering = SpectralClustering(
            n_clusters=n_clusters,
            affinity='precomputed',
            assign_labels='discretize',
            random_state=0
        )
        sku_cluster_labels = clustering.fit_predict(S_sku)

        sku_to_cluster = {sku: cluster for sku, cluster in zip(skus_by_freq, sku_cluster_labels)}

        # 6ï¸âƒ£ êµ°ì§‘ë³„ SKU ëª¨ìŒ
        cluster_to_skus = defaultdict(list)
        for sku, cluster in sku_to_cluster.items():
            cluster_to_skus[cluster].append(sku)

        # 7ï¸âƒ£ Zone ì •ë³´
        rack_labels = list(self.od_matrix.index[2:])
        zone_labels = list(set(rack_labels))
        zone_dist_start = self.od_matrix.loc[self.start_location, zone_labels].to_dict()
        ordered_zones = sorted(zone_labels, key=lambda z: zone_dist_start[z])

        # Zone â†” ë™ ë§¤í•‘ ë° ìš©ëŸ‰
        zone_to_racks = {z: [z] for z in zone_labels}
        zone_remaining = {
            z: len(racks) * self.params.rack_capacity
            for z, racks in zone_to_racks.items()
        }

        # ê³µì¶œí˜„ ê¸°ë°˜ êµ°ì§‘ ìˆœì„œ
        cluster_graph = nx.Graph()
        cluster_ids = list(cluster_to_skus.keys())
        for c1, c2 in combinations(cluster_ids, 2):
            weight = 0
            for sku1 in cluster_to_skus[c1]:
                for sku2 in cluster_to_skus[c2]:
                    weight += self.cooc.get((sku1, sku2), 0)
            cluster_graph.add_edge(c1, c2, weight=weight)

        cluster_order = sorted(
            cluster_graph.nodes,
            key=lambda c: -sum(attr['weight'] for attr in dict(cluster_graph[c]).values())
        )

        # 8ï¸âƒ£ SKU â†’ Zone & ë™ ë§¤í•‘ (ë¶„í•  ë°°ì •)
        sku_to_loc = {}
        rack_capacity = self.params.rack_capacity

        for c in cluster_order:
            skus_in_cluster = cluster_to_skus[c]
            sku_idx = 0

            for z in ordered_zones:
                if sku_idx >= len(skus_in_cluster):
                    break

                racks_in_zone = zone_to_racks[z]
                racks_in_zone_sorted = sorted(
                    racks_in_zone,
                    key=lambda r: self.od_matrix.loc[self.start_location, r]
                )

                current_rack_idx = 0
                current_rack_fill = 0

                while sku_idx < len(skus_in_cluster) and zone_remaining[z] > 0:
                    if current_rack_fill >= rack_capacity:
                        current_rack_idx += 1
                        current_rack_fill = 0
                    if current_rack_idx >= len(racks_in_zone_sorted):
                        break

                    sku = skus_in_cluster[sku_idx]
                    rack = racks_in_zone_sorted[current_rack_idx]

                    sku_to_loc[sku] = rack
                    current_rack_fill += 1
                    zone_remaining[z] -= 1
                    sku_idx += 1

            if sku_idx < len(skus_in_cluster):
                raise ValueError(
                    f"ì „ì²´ Zoneì— ì¶©ë¶„í•œ ìš©ëŸ‰ì´ ì—†ì–´ cluster {c}ì˜ SKU ì¼ë¶€ë¥¼ ë°°ì¹˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )

        # ğŸ”Ÿ ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_loc)

        # ì†ì„±ì— ì¶”ê°€
        self.ordered_zone = ordered_zones
        self.rack_to_zone = {}
        for zone, racks in zone_to_racks.items():
            for rack in racks:
                self.rack_to_zone[rack] = zone'''



#ë™ì€ ê³ ì •ì´ë¯€ë¡œ ë ˆì´ì•„ì›ƒë§Œì„ ì‚¬ìš©
    '''def solve_storage_location(self) -> None:
        import networkx as nx
        epsilon = 1e-3
        # 1ï¸âƒ£ SKU ë¹ˆë„
        freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2ï¸âƒ£ SKU ê°„ ê³µì¶œí˜„ (Jaccard)
        order_dict = defaultdict(set)
        for ord_no, sku in self.orders[['ORD_NO', 'SKU_CD']].values:
            order_dict[sku].add(ord_no)
        #n_clusters = int(self.orders['NUM_PCS'].sum() / self.params.cart_capacity)
        self.cooc = {}
        for a, b in combinations(skus_by_freq, 2):
            inter = len(order_dict[a] & order_dict[b])
            union = len(order_dict[a] | order_dict[b])
            if union > 0:
                jaccard = inter / union
                self.cooc[(a, b)] = jaccard
                self.cooc[(b, a)] = jaccard

        # 3ï¸âƒ£ SKU í´ëŸ¬ìŠ¤í„°ë§
        n_clusters = int(np.ceil(len(skus_by_freq) / self.params.rack_capacity))
        sku_labels = skus_by_freq
        S_sku = np.zeros((len(sku_labels), len(sku_labels)))
        for i, a in enumerate(sku_labels):
            for j, b in enumerate(sku_labels):
                S_sku[i, j] = self.cooc.get((a, b), epsilon)

        clustering = SpectralClustering(
            n_clusters=n_clusters,
            affinity='precomputed',
            assign_labels='discretize', #Kmean
            random_state=0
        )
        sku_cluster_labels = clustering.fit_predict(S_sku)

        sku_to_cluster = {sku: cluster for sku, cluster in zip(sku_labels, sku_cluster_labels)}

        # 4ï¸âƒ£ í´ëŸ¬ìŠ¤í„°ë³„ SKU ëª¨ìŒ
        cluster_to_skus = defaultdict(list)
        for sku, cluster in sku_to_cluster.items():
            cluster_to_skus[cluster].append(sku)

        # 5ï¸âƒ£ Zone ì •ë³´
        rack_labels = list(self.od_matrix.index[2:])
        zone_labels = list(set(rack_labels))
        zone_dist_start = self.od_matrix.loc[self.start_location, zone_labels].to_dict()
        ordered_zones = sorted(zone_labels, key=lambda z: zone_dist_start[z])

        # Zone â†” ë™ ë§¤í•‘ ë° ìš©ëŸ‰
        zone_to_racks = {z: [z] for z in zone_labels}
        zone_remaining = {
            z: len(racks) * self.params.rack_capacity
            for z, racks in zone_to_racks.items()
        }

        # ê³µì¶œí˜„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„° ìˆœì„œ
        cluster_graph = nx.Graph()
        for c1, c2 in combinations(range(n_clusters), 2):
            weight = 0
            for sku1 in cluster_to_skus[c1]:
                for sku2 in cluster_to_skus[c2]:
                    weight += self.cooc.get((sku1, sku2), epsilon)
            cluster_graph.add_edge(c1, c2, weight=weight)

        cluster_order = sorted(
            cluster_graph.nodes,
            key=lambda c: -sum(attr['weight'] for attr in dict(cluster_graph[c]).values())
        )

        # SKU â†’ Zone & ë™ ë§¤í•‘ (ë¶„í•  ë°°ì •)
        sku_to_loc = {}
        rack_capacity = self.params.rack_capacity

        for c in cluster_order:
            skus_in_cluster = cluster_to_skus[c]
            sku_idx = 0

            for z in ordered_zones:
                if sku_idx >= len(skus_in_cluster):
                    break

                racks_in_zone = zone_to_racks[z]
                racks_in_zone_sorted = sorted(
                    racks_in_zone,
                    key=lambda r: self.od_matrix.loc[self.start_location, r]
                )

                current_rack_idx = 0
                current_rack_fill = 0

                while sku_idx < len(skus_in_cluster) and zone_remaining[z] > 0:
                    if current_rack_fill >= rack_capacity:
                        current_rack_idx += 1
                        current_rack_fill = 0
                    if current_rack_idx >= len(racks_in_zone_sorted):
                        break

                    sku = skus_in_cluster[sku_idx]
                    rack = racks_in_zone_sorted[current_rack_idx]

                    sku_to_loc[sku] = rack
                    current_rack_fill += 1
                    zone_remaining[z] -= 1
                    sku_idx += 1

            if sku_idx < len(skus_in_cluster):
                raise ValueError(
                    f"ì „ì²´ Zoneì— ì¶©ë¶„í•œ ìš©ëŸ‰ì´ ì—†ì–´ cluster {c}ì˜ SKU ì¼ë¶€ë¥¼ ë°°ì¹˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                )

        # ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_loc)

        # ì†ì„±ì— ì¶”ê°€
        self.ordered_zone = ordered_zones
        self.rack_to_zone = {}
        for zone, racks in zone_to_racks.items():
            for rack in racks:
                self.rack_to_zone[rack] = zone

'''
#TSP ì¶”ê°€

    '''def solve_storage_location(self) -> None:
        import networkx as nx
        # 1. SKU frequency
        if 'NUM_PCS' in self.orders.columns:
            freq = self.orders.groupby('SKU_CD')['NUM_PCS'].sum()
        else:
            freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2. SKU co-occurrence matrix (Jaccard similarity)
        order_dict = defaultdict(set)
        for ord_no, sku in self.orders[['ORD_NO', 'SKU_CD']].values:
            order_dict[sku].add(ord_no)

        cooc = {}
        for a, b in combinations(skus_by_freq, 2):
            inter = len(order_dict[a] & order_dict[b])
            union = len(order_dict[a] | order_dict[b])
            if union > 0:
                jaccard = inter / union
                cooc[(a, b)] = jaccard
                cooc[(b, a)] = jaccard

        # 3. Rack distance matrix and similarity
        rack_labels = list(self.od_matrix.index[2:])
        D = self.od_matrix.loc[rack_labels, rack_labels].values
        sigma = np.std(D)
        S = np.exp(-D**2 / (2 * sigma**2))

        # 4. Spectral Clustering for rack zones
        n_zones = int(np.ceil(len(skus_by_freq) / self.params.rack_capacity))
        clustering = SpectralClustering(
            n_clusters=n_zones,
            affinity='precomputed',
            assign_labels='kmeans',
            random_state=0
        )
        labels = clustering.fit_predict(S)
        zone_to_racks = defaultdict(list)
        rack_to_zone = {}
        for rack, z in zip(rack_labels, labels):
            zone_to_racks[z].append(rack)
            rack_to_zone[rack] = z

        # 5. Zone entrance distance
        dist_start = self.od_matrix.loc[self.start_location, rack_labels]
        zone_dist = {
            z: np.mean([dist_start[r] for r in racks])
            for z, racks in zone_to_racks.items()
        }

        # 6. SKU clustering into rack-sized groups
        assigned = set()
        clusters = []
        for sku in skus_by_freq:
            if sku in assigned:
                continue
            cluster = {sku}
            candidates = [s for s in skus_by_freq if s not in assigned and s != sku]
            candidates.sort(key=lambda x: cooc.get((sku, x), 0), reverse=True)
            for c in candidates:
                if len(cluster) >= self.params.rack_capacity:
                    break
                cluster.add(c)
            assigned |= cluster
            clusters.append(cluster)

        # 7. Assign each SKU to a zone
        sku_to_zone = {}
        for i, cluster in enumerate(clusters):
            best_zone = i % n_zones  # initial naive assignment
            for sku in cluster:
                sku_to_zone[sku] = best_zone

        # 8. Build zone co-occurrence
        zone_cooc = defaultdict(int)
        for _, grp in self.orders.groupby('ORD_NO'):
            zones = {sku_to_zone.get(sku, -1) for sku in grp['SKU_CD'] if sku in sku_to_zone}
            zones = list(zones)
            for i in range(len(zones)):
                for j in range(i+1, len(zones)):
                    z1, z2 = zones[i], zones[j]
                    zone_cooc[(z1, z2)] += 1
                    zone_cooc[(z2, z1)] += 1

        # 9. Zone graph with distance / (1 + co-occurrence) weights
        zone_list = list(zone_to_racks.keys())
        G = nx.Graph()
        for i, zi in enumerate(zone_list):
            for j, zj in enumerate(zone_list):
                if i == j:
                    continue
                dist = abs(zone_dist[zi] - zone_dist[zj])
                cooc_score = zone_cooc.get((zi, zj), 0)
                weight = dist / (1 + cooc_score)
                G.add_edge(zi, zj, weight=weight)

        # 10. TSP for zone ordering
        tsp_path = nx.approximation.traveling_salesman_problem(G, cycle=False)
        ordered_zones = tsp_path

        # 11. Assign racks based on ordered zones
        rack_sequence = []
        for z in ordered_zones:
            racks = sorted(zone_to_racks[z], key=lambda r: dist_start[r])
            rack_sequence.extend(racks)

        # 12. SKU to location
        sku_to_location = {}
        for cluster, rack in zip(clusters, rack_sequence):
            combined = {
                s: 0.6 * freq.get(s, 0) +
                   0.4 * sum(cooc.get((s, t), 0) for t in cluster if t != s)
                for s in cluster
            }
            sorted_skus = sorted(cluster, key=lambda s: combined[s], reverse=True)
            for sku in sorted_skus:
                sku_to_location[sku] = rack
        self.cooc = cooc
        self.rack_to_zone = rack_to_zone
        self.ordered_zones = ordered_zones
        self.zone_cooc = zone_cooc
        # 13. Reflect result
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_location)
'''

# ZONE ê±°ë¦¬ í´ëŸ¬ìŠ¤íŒ… -> sku ì£¼ë¬¸ë¹ˆë„ ë° ì—°ê´€ì„± í´ëŸ¬ìŠ¤íŒ… -> ZONE í¬ê¸°ë¡œ sku ë”ë¯¸ ìƒì„± -> ê·¸ë¦¬ë“œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ë”ë¯¸ë¼ë¦¬ì˜ ì—°ê´€ì„± íŒŒì•… -> ì—°ê´€ì„± ê¸°ë°˜ zone ë§¤í•‘ -> zone ë‚´ì— ë°°ì¹˜ ì „ëµ ì ìš©
    '''def solve_storage_location(self) -> None:
        """Solve SLAP using:
           - SKU ë¹ˆë„Â·ì—°ê´€ì„± ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
           - Spectral Clustering ìœ¼ë¡œ ë™ Zone ë¶„í• 
           - ê·¸ë¦¬ë”” íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ Zone ìˆœì„œ ê²°ì •
           - ë™ ë‚´ë¶€ ì •ë ¬(ë¹ˆë„+ì—°ê´€ì„± ê¸°ë°˜)"""
        from collections import defaultdict
        from itertools import combinations
        import numpy as np
        from sklearn.cluster import SpectralClustering

        # 1. SKU ì¶œê³  ë¹ˆë„ ê³„ì‚°
        if 'NUM_PCS' in self.orders.columns:
            freq = self.orders.groupby('SKU_CD')['NUM_PCS'].sum()
        else:
            freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2. SKU ê³µë™ ì£¼ë¬¸ ì—°ê´€ì„± ê³„ì‚°
        cooc = defaultdict(int)
        for _, grp in self.orders.groupby('ORD_NO'):
            items = grp['SKU_CD'].tolist()
            for a, b in combinations(items, 2):
                cooc[(a, b)] += 1
                cooc[(b, a)] += 1

        # 3. ë™ ìœ„ì¹˜ ë° ê±°ë¦¬ ì¤€ë¹„
        rack_labels = list(self.od_matrix.index[2:])  # WP_000x...
        D = self.od_matrix.loc[rack_labels, rack_labels].values
        sigma = np.std(D)
        S = np.exp(-D**2 / (2 * sigma**2))  # ê°€ìš°ì‹œì•ˆ ìœ ì‚¬ë„

        # 4. Spectral Clustering ìœ¼ë¡œ ë™ì„ Zone ë¶„í• 
        n_zones = int(np.ceil(len(skus_by_freq) / self.params.rack_capacity))
        clustering = SpectralClustering(
            n_clusters=n_zones,
            affinity='precomputed',
            assign_labels='kmeans',
            random_state=0
        )
        labels = clustering.fit_predict(S)
        zone_to_racks = defaultdict(list)
        rack_to_zone = {}
        for rack, z in zip(rack_labels, labels):
            zone_to_racks[z].append(rack)
            rack_to_zone[rack] = z

        # 5. ì´ˆê¸° Zone ìˆœì„œ: ì…êµ¬ ê¸°ì¤€ ê±°ë¦¬ë§Œìœ¼ë¡œ ì •ë ¬
        dist_start = self.od_matrix.loc[self.start_location, rack_labels]
        zone_dist = {
            z: np.mean([dist_start[r] for r in racks])
            for z, racks in zone_to_racks.items()
        }
        initial_ordered_zones = sorted(zone_to_racks.keys(), key=lambda z: zone_dist[z])
        initial_rack_sorted = []
        for z in initial_ordered_zones:
            racks = zone_to_racks[z][:]
            racks.sort(key=lambda r: dist_start[r])
            initial_rack_sorted.extend(racks)

        # 6. SKU í´ëŸ¬ìŠ¤í„°ë§ (ë¹ˆë„+ì—°ê´€ì„± ê¸°ë°˜)
        assigned = set()
        clusters = []
        for sku in skus_by_freq:
            if sku in assigned:
                continue
            cluster = {sku}
            candidates = [s for s in skus_by_freq if s not in assigned]
            candidates.sort(key=lambda x: cooc.get((sku, x), 0), reverse=True)
            for c in candidates:
                if len(cluster) < self.params.rack_capacity:
                    cluster.add(c)
                else:
                    break
            assigned |= cluster
            clusters.append(cluster)

        # 7. ì´ˆê¸° SKUâ†’ë™ ë§¤í•‘ ë° SKUâ†’Zone ë§¤í•‘
        sku_to_initial_rack = {}
        for i, cluster in enumerate(clusters):
            rack = initial_rack_sorted[i]
            for sku in cluster:
                sku_to_initial_rack[sku] = rack
        sku_to_zone = {sku: rack_to_zone[r] for sku, r in sku_to_initial_rack.items()}

        # 8. Zone ê°„ ê³µë™ ì£¼ë¬¸ ì—°ê´€ì„± ê³„ì‚°
        zone_cooc = defaultdict(int)
        for _, grp in self.orders.groupby('ORD_NO'):
            zones = {sku_to_zone[sku] for sku in grp['SKU_CD']}
            for z1, z2 in combinations(zones, 2):
                zone_cooc[(z1, z2)] += 1
                zone_cooc[(z2, z1)] += 1

        # 9. ê·¸ë¦¬ë”” íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ìµœì¢… Zone ìˆœì„œ ê²°ì •
        w_dist, w_cooc = 0.5, 0.5
        def zone_score(cur, nxt):
            return w_cooc * zone_cooc.get((cur, nxt), 0) - w_dist * zone_dist[nxt]

        all_zones = list(zone_to_racks.keys())
        current = min(all_zones, key=lambda z: zone_dist[z])  # ì…êµ¬ì— ê°€ì¥ ê°€ê¹Œìš´ Zone
        ordered_zones = [current]
        remaining = set(all_zones) - {current}
        while remaining:
            nxt = max(remaining, key=lambda z: zone_score(current, z))
            ordered_zones.append(nxt)
            remaining.remove(nxt)
            current = nxt

        # 10. ìµœì¢… rack_sorted ì¬êµ¬ì„±
        final_rack_sorted = []
        for z in ordered_zones:
            racks = zone_to_racks[z][:]
            racks.sort(key=lambda r: dist_start[r])
            final_rack_sorted.extend(racks)

        # 11. ìµœì¢… SKUâ†’ë™ ë§¤í•‘ (í´ëŸ¬ìŠ¤í„° ë‹¨ìœ„ + ë‚´ë¶€ ì •ë ¬)
        sku_to_location = {}
        for idx, cluster in enumerate(clusters):
            rack = final_rack_sorted[idx]
            # ë™ ë‚´ë¶€ ì •ë ¬: ë¹ˆë„ 70%, ì—°ê´€ì„± 30%
            combined = {
                s: 0.7 * freq.get(s, 0) + 
                   0.3 * sum(cooc.get((s, t), 0) for t in cluster if t != s)
                for s in cluster
            }
            sorted_skus = sorted(cluster, key=lambda s: combined[s], reverse=True)
            for sku in sorted_skus:
                sku_to_location[sku] = rack

        # 12. ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_location)'''
    
    
    # Re-define fast SLAP solver
    '''def solve_storage_location(self) -> pd.DataFrame:
        import time
        from itertools import combinations
        from sklearn.cluster import KMeans
        from sklearn.decomposition import PCA
        start_time = time.time()
        if 'NUM_PCS' in self.orders.columns:
            freq = self.orders.groupby('SKU_CD')['NUM_PCS'].sum()
        else:
            freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        cooc = defaultdict(int)
        top_skus = set(skus_by_freq[:200])
        for _, grp in self.orders.groupby('ORD_NO'):
            items = [sku for sku in grp['SKU_CD'] if sku in top_skus]
            for a, b in combinations(items, 2):
                cooc[(a, b)] += 1
                cooc[(b, a)] += 1

        rack_labels = list(self.od_matrix.index[2:])
        D = self.od_matrix.loc[rack_labels, rack_labels].values

        n_zones = min(int(np.ceil(len(skus_by_freq) / self.params.rack_capacity)), 40)
        D_sym = (D + D.T) / 2
        pca = PCA(n_components=10)
        X = pca.fit_transform(D_sym)
        clustering = KMeans(n_clusters=n_zones, random_state=0, n_init=10)
        labels = clustering.fit_predict(X)
        zone_to_racks = defaultdict(list)
        rack_to_zone = {}
        for rack, z in zip(rack_labels, labels):
            zone_to_racks[z].append(rack)
            rack_to_zone[rack] = z

        dist_start = self.od_matrix.loc[self.start_location, rack_labels]
        zone_dist = {
            z: np.mean([dist_start[r] for r in racks])
            for z, racks in zone_to_racks.items()
        }

        initial_ordered_zones = sorted(zone_to_racks.keys(), key=lambda z: zone_dist[z])
        initial_rack_sorted = []
        for z in initial_ordered_zones:
            racks = zone_to_racks[z][:]
            racks.sort(key=lambda r: dist_start[r])
            initial_rack_sorted.extend(racks)

        assigned = set()
        clusters = []
        for sku in skus_by_freq:
            if sku in assigned:
                continue
            cluster = {sku}
            for other in skus_by_freq:
                if other not in assigned and len(cluster) < self.params.rack_capacity:
                    cluster.add(other)
            assigned |= cluster
            clusters.append(cluster)

        sku_to_location = {}
        for idx, cluster in enumerate(clusters):
            if idx >= len(initial_rack_sorted):
                break
            rack = initial_rack_sorted[idx]
            sorted_skus = sorted(
                cluster,
                key=lambda s: 0.7 * freq.get(s, 0) + 0.3 * sum(cooc.get((s, t), 0) for t in cluster if t != s),
                reverse=True
            )
            for sku in sorted_skus:
                sku_to_location[sku] = rack

        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_location)

        elapsed_time = time.time() - start_time
        return self.orders'''
    
    

# ì£¼ë¬¸ ë¹ˆë„ìˆ˜, ìƒí’ˆ ì—°ê´€ì„±, ë™ ìœ„ì¹˜ì˜ ëŒ€ì¹­ì„±ì„ ê³ ë ¤í•œ SLAP
# ë™ì„ zoneìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ -> ê°€ê¹Œìš´ zoneë¶€í„° ë¹ˆë„ìˆ˜ ë° ì—°ê´€ì„±
    '''def solve_storage_location(self) -> None:
        #Solve Storage Location Assignment Problem (SLAP) using SKU frequency, co-occurrence clustering, and spectral clustering for rack zones
        from collections import defaultdict
        from itertools import combinations
        import numpy as np
        from sklearn.cluster import SpectralClustering

        # 1. SKU ì¶œê³  ë¹ˆë„ ê³„ì‚°
        if 'NUM_PCS' in self.orders.columns:
            freq = self.orders.groupby('SKU_CD')['NUM_PCS'].sum()
        else:
            freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2. SKU ê°„ ê³µë™ ì£¼ë¬¸ ì—°ê´€ì„± ê³„ì‚°
        cooc = defaultdict(int)
        for _, group in self.orders.groupby('ORD_NO'):
            for a, b in combinations(group['SKU_CD'], 2):
                cooc[(a, b)] += 1
                cooc[(b, a)] += 1

        # 3. ë™ ìœ„ì¹˜ ë° ê±°ë¦¬ í–‰ë ¬ ì¤€ë¹„
        rack_locations = list(self.od_matrix.index[2:])
        D = self.od_matrix.loc[rack_locations, rack_locations].values
        # ìœ ì‚¬ë„ í–‰ë ¬ ìƒì„± (ê°€ìš°ì‹œì•ˆ ì»¤ë„)
        sigma = np.std(D)
        S = np.exp(-D**2 / (2 * sigma**2))

        # 4. ë™ ZONE ë¶„í•  via Spectral Clustering
        n_clusters = int(np.ceil(len(skus_by_freq) / self.params.rack_capacity))
        clustering = SpectralClustering(
            n_clusters=n_clusters,
            affinity='precomputed',
            assign_labels='kmeans'
        )
        labels = clustering.fit_predict(S)
        zone_to_racks = {}
        for rack, label in zip(rack_locations, labels):
            zone_to_racks.setdefault(label, []).append(rack)

        # 5. ë™ ìˆœì„œ ê²°ì •: ì¡´ ìˆœì„œ + ì‹œì‘ ìœ„ì¹˜ ê±°ë¦¬ ê¸°ì¤€ ì •ë ¬
        dist_start = self.od_matrix.loc[self.start_location, rack_locations]
        rack_sorted = []
        for label in sorted(zone_to_racks.keys()):
            racks = zone_to_racks[label]
            racks.sort(key=lambda r: dist_start[r])
            rack_sorted.extend(racks)

        # 6. SKU í´ëŸ¬ìŠ¤í„°ë§ (ë¹ˆë„ + ì—°ê´€ì„±)
        assigned = set()
        clusters = []
        for sku in skus_by_freq:
            if sku in assigned:
                continue
            cluster = {sku}
            candidates = [s for s in skus_by_freq if s not in assigned]
            candidates.sort(key=lambda x: cooc.get((sku, x), 0), reverse=True)
            for c in candidates:
                if len(cluster) < self.params.rack_capacity:
                    cluster.add(c)
                else:
                    break
            assigned |= cluster
            clusters.append(cluster)

        # 7. SKU í´ëŸ¬ìŠ¤í„°ë¥¼ ë™ì— ë§¤í•‘
        sku_to_location = {}
        for i, cluster in enumerate(clusters):
            rack = rack_sorted[i] if i < len(rack_sorted) else rack_sorted[i % len(rack_sorted)]
            for sku in cluster:
                sku_to_location[sku] = rack

        # 8. ë‚¨ì€ SKU ì²˜ë¦¬
        remaining = [s for s in skus_by_freq if s not in sku_to_location]
        for idx, sku in enumerate(remaining, start=len(clusters)):
            rack = rack_sorted[idx % len(rack_sorted)]
            sku_to_location[sku] = rack

        # 9. ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_location)'''

    '''def solve_storage_location(self) -> None:
        import networkx as nx
        from sklearn.cluster import SpectralClustering
        import numpy as np
        from collections import defaultdict
        from itertools import combinations

        # 1ï¸âƒ£ SKU ë¹ˆë„
        freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2ï¸âƒ£ SKU ê°„ ê³µì¶œí˜„ (Jaccard)
        order_dict = defaultdict(set)
        for ord_no, sku in self.orders[['ORD_NO', 'SKU_CD']].values:
            order_dict[sku].add(ord_no)

        self.cooc = {}
        for a, b in combinations(skus_by_freq, 2):
            inter = len(order_dict[a] & order_dict[b])
            union = len(order_dict[a] | order_dict[b])
            if union > 0:
                jaccard = inter / union
                self.cooc[(a, b)] = jaccard
                self.cooc[(b, a)] = jaccard

        # 3ï¸âƒ£ SKU í´ëŸ¬ìŠ¤í„°ë§ (ê³µì¶œí˜„ ê¸°ë°˜)
        n_clusters = int(np.ceil(len(skus_by_freq) / self.params.rack_capacity))
        S_sku = np.zeros((len(skus_by_freq), len(skus_by_freq)))
        for i, a in enumerate(skus_by_freq):
            for j, b in enumerate(skus_by_freq):
                S_sku[i, j] = self.cooc.get((a, b), 0)

        clustering = SpectralClustering(
            n_clusters=n_clusters,
            affinity='precomputed',
            assign_labels='discretize',
            random_state=0
        )
        sku_cluster_labels = clustering.fit_predict(S_sku)

        sku_to_cluster = {sku: cluster for sku, cluster in zip(skus_by_freq, sku_cluster_labels)}

        # 4ï¸âƒ£ í´ëŸ¬ìŠ¤í„°ë³„ SKUì™€ ìš°ì„ ìˆœìœ„ ê³„ì‚°
        cluster_to_skus = defaultdict(list)
        cluster_priority = {}
        for sku, cluster in sku_to_cluster.items():
            cluster_to_skus[cluster].append(sku)

        for cluster, skus in cluster_to_skus.items():
            cluster_priority[cluster] = sum(freq[sku] for sku in skus)

        # 5ï¸âƒ£ Zone ì •ë³´
        rack_labels = list(self.od_matrix.index[2:])
        zone_labels = list(set(rack_labels))
        zone_dist_start = self.od_matrix.loc[self.start_location, zone_labels].to_dict()
        ordered_zones = sorted(zone_labels, key=lambda z: zone_dist_start[z])

        # 6ï¸âƒ£ Zone â†” ë™ ë§¤í•‘
        zone_to_racks = {z: [z] for z in zone_labels}
        zone_remaining = {
            z: len(racks) * self.params.rack_capacity
            for z, racks in zone_to_racks.items()
        }

        # 7ï¸âƒ£ í´ëŸ¬ìŠ¤í„° ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
        clusters_ordered = sorted(cluster_to_skus.keys(), key=lambda c: -cluster_priority[c])

        # ğŸ”· SKU â†’ LOC í• ë‹¹
        sku_to_loc = {}
        rack_capacity = self.params.rack_capacity
        used_zones = set()

        for c in clusters_ordered:
            skus_in_cluster = cluster_to_skus[c]
            sku_idx = 0
            candidate_zones = ordered_zones[:]  # Zone í›„ë³´ ë¦¬ìŠ¤íŠ¸

            while sku_idx < len(skus_in_cluster):
                # ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•Šì€ Zone ë˜ëŠ” ë‚¨ì€ ìš©ëŸ‰ì´ ìˆëŠ” Zone ì„ íƒ
                best_zone = None
                for z in candidate_zones:
                    if zone_remaining[z] > 0:
                        best_zone = z
                        break
                if best_zone is None:
                    raise ValueError(f"ì „ì²´ Zoneì— ì¶©ë¶„í•œ ìš©ëŸ‰ì´ ì—†ì–´ cluster {c}ì˜ SKU ì¼ë¶€ë¥¼ ë°°ì¹˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                racks_in_zone = zone_to_racks[best_zone]
                racks_in_zone_sorted = sorted(
                    racks_in_zone,
                    key=lambda r: self.od_matrix.loc[self.start_location, r]
                )

                current_rack_idx = 0
                current_rack_fill = 0

                while sku_idx < len(skus_in_cluster) and zone_remaining[best_zone] > 0:
                    if current_rack_fill >= rack_capacity:
                        current_rack_idx += 1
                        current_rack_fill = 0
                    if current_rack_idx >= len(racks_in_zone_sorted):
                        break

                    sku = skus_in_cluster[sku_idx]
                    rack = racks_in_zone_sorted[current_rack_idx]

                    sku_to_loc[sku] = rack
                    current_rack_fill += 1
                    zone_remaining[best_zone] -= 1
                    sku_idx += 1

                used_zones.add(best_zone)

        # ğŸ”Ÿ ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_loc)

        # ì†ì„±ì— ì¶”ê°€
        self.ordered_zone = ordered_zones
        self.rack_to_zone = {}
        for zone, racks in zone_to_racks.items():
            for rack in racks:
                self.rack_to_zone[rack] = zone'''


#ì£¼ë¬¸ ë¹ˆë„ ìˆ˜ì™€ ìƒí’ˆ ì—°ê´€ì„± ê³ ë ¤í•œ SLAP

    def solve_storage_location(self) -> None:
        """Solve Storage Location Assignment Problem (SLAP) using SKU frequency and co-occurrence clustering"""
        from collections import defaultdict
        from itertools import combinations

        # 1. SKU ì¶œê³  ë¹ˆë„ ê³„ì‚° (NUM_PCSê°€ ì—†ìœ¼ë©´ ì£¼ë¬¸ ê±´ìˆ˜ ê¸°ì¤€)
        if 'NUM_PCS' in self.orders.columns:
            freq = self.orders.groupby('SKU_CD')['NUM_PCS'].sum()
        else:
            freq = self.orders.groupby('SKU_CD').size()
        skus_by_freq = freq.sort_values(ascending=False).index.tolist()

        # 2. SKU ê°„ ê³µë™ ì£¼ë¬¸ ì—°ê´€ì„±(co-occurrence) ê³„ì‚°
        cooc = defaultdict(int)
        for _, group in self.orders.groupby('ORD_NO'):
            for a, b in combinations(group['SKU_CD'], 2):
                cooc[(a, b)] += 1
                cooc[(b, a)] += 1
        self.cooc = cooc
        # 3. ì‹œì‘ ì§€ì ì—ì„œ ê°€ê¹Œìš´ ë™ë¶€í„° ì •ë ¬
        rack_locations = self.od_matrix.index[2:]
        dist_start = self.od_matrix.loc[self.start_location, rack_locations]
        rack_sorted = dist_start.sort_values().index.tolist()

        # 4. ê·¸ë¦¬ë”” í´ëŸ¬ìŠ¤í„°ë§: ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ SKUë“¤ì„ ê°™ì€ í´ëŸ¬ìŠ¤í„°(ë™)ë¡œ ë¬¶ê¸°
        assigned = set()
        clusters = []
        for sku in skus_by_freq:
            if sku in assigned:
                continue
            cluster = {sku}
            candidates = [s for s in skus_by_freq if s not in assigned]
            # ì—°ê´€ì„± ë†’ì€ ìˆœ ì •ë ¬
            candidates.sort(key=lambda x: cooc.get((sku, x), 0), reverse=True)
            for c in candidates:
                if len(cluster) < self.params.rack_capacity:
                    cluster.add(c)
                else:
                    break
            assigned |= cluster
            clusters.append(cluster)

        # 5. í´ëŸ¬ìŠ¤í„°ë¥¼ ë™ì— ë§¤í•‘
        sku_to_location = {}
        for rack, cluster in zip(rack_sorted, clusters):
            for sku in cluster:
                sku_to_location[sku] = rack

        # 6. í• ë‹¹ë˜ì§€ ì•Šì€ ë‚¨ì€ SKU ì²˜ë¦¬ (ëœë¤ ë˜ëŠ” ë¹ˆë„ ìˆœ)
        remaining = [s for s in skus_by_freq if s not in sku_to_location]
        idx = len(clusters)
        for sku in remaining:
            rack = rack_sorted[idx // self.params.rack_capacity]
            sku_to_location[sku] = rack
            idx += 1
        print(len(remaining))
        # ê²°ê³¼ ë°˜ì˜
        self.orders['LOC'] = self.orders['SKU_CD'].map(sku_to_location)


#FIFO(OBSP)
    '''def solve_order_batching(self) -> None:
        """Solve Order Batching and Sequencing Problem (OBSP) using FIFO strategy"""
        unique_orders = sorted(self.orders['ORD_NO'].unique())
        num_carts = len(unique_orders) // self.params.cart_capacity + 1
        
        order_to_cart = {}
        for cart_no in range(1, num_carts + 1):
            start_idx = (cart_no - 1) * self.params.cart_capacity
            end_idx = start_idx + self.params.cart_capacity
            cart_orders = unique_orders[start_idx:end_idx]
            for order in cart_orders:
                order_to_cart[order] = cart_no

        self.orders['CART_NO'] = self.orders['ORD_NO'].map(order_to_cart)'''
#ë‹¨ìˆœ ê·¸ë¦¬ë“œí´ëŸ¬ìŠ¤í„°ë§ ë°°ì¹˜ì— ê´€í•œ OBSP
    def solve_order_batching(self) -> None:
        """Solve OBSP: ì£¼ë¬¸ì„ ì¹´íŠ¸ì— ë°°ì¹˜í•˜ê³ , ì¹´íŠ¸ë³„ ZONE ìˆœì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ SEQ ì§€ì •"""
        from collections import defaultdict

        # 1ï¸âƒ£ ì£¼ë¬¸ë³„ SKU ëª©ë¡
        order_skus = self.orders.groupby('ORD_NO')['SKU_CD'].apply(list).to_dict()
        order_locs = self.orders.groupby('ORD_NO')['LOC'].apply(list).to_dict()

        # 2ï¸âƒ£ ì£¼ë¬¸ë³„ Zone (ë™) ì§‘í•©
        order_zones = {
            ord_no: set(order_locs[ord_no])
            for ord_no in order_locs
        }

        order_ids = list(order_skus.keys())

        # 3ï¸âƒ£ ì£¼ë¬¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (SKU ì—°ê´€ì„±ì˜ í•©)
        order_sim = defaultdict(float)
        for i in range(len(order_ids)):
            for j in range(i+1, len(order_ids)):
                o1, o2 = order_ids[i], order_ids[j]
                sim = sum(
                    self.cooc.get((s1, s2), 0)
                    for s1 in order_skus[o1]
                    for s2 in order_skus[o2]
                )
                order_sim[(o1, o2)] = sim
                order_sim[(o2, o1)] = sim

        # 4ï¸âƒ£ ì£¼ë¬¸ë³„ ìœ ì‚¬ ì´ì›ƒ ì •ë ¬
        neighbors = {o: [] for o in order_ids}
        for (o1, o2), sim in order_sim.items():
            neighbors[o1].append((o2, sim))
        for o in neighbors:
            neighbors[o].sort(key=lambda x: -x[1])  # ìœ ì‚¬ë„ ë‚´ë¦¼ì°¨ìˆœ

        # 5ï¸âƒ£ Greedy Batching
        assigned = set()
        order_to_cart = {}
        cart_no = 1
        for o in order_ids:
            if o in assigned:
                continue
            batch = [o]
            assigned.add(o)
            for cand, _ in neighbors[o]:
                if len(batch) >= self.params.cart_capacity:
                    break
                if cand not in assigned:
                    batch.append(cand)
                    assigned.add(cand)
            for ord_id in batch:
                order_to_cart[ord_id] = cart_no
            cart_no += 1

        self.orders['CART_NO'] = self.orders['ORD_NO'].map(order_to_cart)

        # 6ï¸âƒ£ ì¹´íŠ¸ë³„ Zone ìˆœì„œë¡œ SEQ ë¶€ì—¬
        # (ì…ì¶œê³ ì§€ì ì—ì„œ ê°€ê¹Œìš´ ë™ ìˆœìœ¼ë¡œ ì¹´íŠ¸ë³„ SEQ ì§€ì •)
        cart_zones = self.orders.groupby('CART_NO')['LOC'].apply(set).to_dict()
        dist_start = self.od_matrix.loc[self.start_location]

        cart_order = sorted(cart_zones.keys(), key=lambda c: min(
            dist_start[loc] for loc in cart_zones[c] if loc in dist_start
        ))
        cart_to_seq = {cart: idx + 1 for idx, cart in enumerate(cart_order)}

        self.orders['SEQ'] = self.orders['CART_NO'].map(cart_to_seq)

#ZONE Spectral clustering
    '''def solve_order_batching(self) -> None:
        """OBSP: ì£¼ë¬¸ ìœ ì‚¬ë„ + ZONE ìˆœì„œë¥¼ ê³ ë ¤í•œ ì¹´íŠ¸ ë°°ì¹˜ ë° ìˆœì„œ"""
        from collections import defaultdict
        import numpy as np

        # 1. ì£¼ë¬¸ë³„ SKU ì§‘í•©
        order_skus = self.orders.groupby('ORD_NO')['SKU_CD'].apply(list).to_dict()
        order_zones = {}
        for ord_no, skus in order_skus.items():
            zones = {self.rack_to_zone.get(self.orders.loc[self.orders['SKU_CD'] == sku, 'LOC'].iat[0], -1)
                     for sku in skus}
            order_zones[ord_no] = zones

        order_ids = list(order_skus.keys())

        # 2. ì£¼ë¬¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        order_sim = defaultdict(float)
        for i in range(len(order_ids)):
            for j in range(i+1, len(order_ids)):
                o1, o2 = order_ids[i], order_ids[j]
                sim = sum(self.cooc.get((s1, s2), 0) for s1 in order_skus[o1] for s2 in order_skus[o2])
                order_sim[(o1, o2)] = sim
                order_sim[(o2, o1)] = sim

        # 3. ì£¼ë¬¸ë³„ ìœ ì‚¬ ì´ì›ƒ ì •ë ¬
        neighbors = {o: [] for o in order_ids}
        for (o1, o2), sim in order_sim.items():
            neighbors[o1].append((o2, sim))
        for o in neighbors:
            neighbors[o].sort(key=lambda x: -x[1])

        # 4. Greedy Batching
        assigned = set()
        order_to_cart = {}
        cart_no = 1
        for o in order_ids:
            if o in assigned:
                continue
            batch = [o]
            assigned.add(o)
            for cand, _ in neighbors[o]:
                if len(batch) >= self.params.cart_capacity:
                    break
                if cand not in assigned:
                    batch.append(cand)
                    assigned.add(cand)
            for ord_id in batch:
                order_to_cart[ord_id] = cart_no
            cart_no += 1
        self.orders['CART_NO'] = self.orders['ORD_NO'].map(order_to_cart)

        # 5. CART_NOë³„ ZONE ìˆœì„œ ê¸°ë°˜ SEQ ë¶€ì—¬
        cart_zones = self.orders.groupby('CART_NO')['LOC'].apply(lambda locs:
            set(self.rack_to_zone[l] for l in locs if l in self.rack_to_zone)).to_dict()

        cart_order = sorted(cart_zones.keys(), key=lambda c: [
            self.ordered_zones.index(z) for z in cart_zones[c] if z in self.ordered_zones
        ])
        cart_to_seq = {cart: idx+1 for idx, cart in enumerate(cart_order)}

        self.orders['SEQ'] = self.orders['CART_NO'].map(cart_to_seq)
'''
# zone Spectral clustering x
    '''def solve_order_batching(self) -> None:
        """OBSP: ì£¼ë¬¸ ìœ ì‚¬ë„ + ZONE ìˆœì„œë¥¼ ê³ ë ¤í•œ ì¹´íŠ¸ ë°°ì¹˜ ë° ìˆœì„œ"""
        from collections import defaultdict

        # 1. ì£¼ë¬¸ë³„ SKU ì§‘í•©
        order_skus = self.orders.groupby('ORD_NO')['SKU_CD'].apply(list).to_dict()
        order_zones = {}
        for ord_no, skus in order_skus.items():
            zones = {self.rack_to_zone.get(self.orders.loc[self.orders['SKU_CD'] == sku, 'LOC'].iat[0], -1)
                     for sku in skus}
            order_zones[ord_no] = zones

        order_ids = list(order_skus.keys())

        # 2. ì£¼ë¬¸ ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        order_sim = defaultdict(float)
        for i in range(len(order_ids)):
            for j in range(i+1, len(order_ids)):
                o1, o2 = order_ids[i], order_ids[j]
                sim = sum(self.cooc.get((s1, s2), 0) for s1 in order_skus[o1] for s2 in order_skus[o2])
                order_sim[(o1, o2)] = sim
                order_sim[(o2, o1)] = sim

        # 3. ì£¼ë¬¸ë³„ ìœ ì‚¬ ì´ì›ƒ ì •ë ¬
        neighbors = {o: [] for o in order_ids}
        for (o1, o2), sim in order_sim.items():
            neighbors[o1].append((o2, sim))
        for o in neighbors:
            neighbors[o].sort(key=lambda x: -x[1])

        # 4. Greedy Batching
        assigned = set()
        order_to_cart = {}
        cart_no = 1
        for o in order_ids:
            if o in assigned:
                continue
            batch = [o]
            assigned.add(o)
            for cand, _ in neighbors[o]:
                if len(batch) >= self.params.cart_capacity:
                    break
                if cand not in assigned:
                    batch.append(cand)
                    assigned.add(cand)
            for ord_id in batch:
                order_to_cart[ord_id] = cart_no
            cart_no += 1
        self.orders['CART_NO'] = self.orders['ORD_NO'].map(order_to_cart)

        # 5. CART_NOë³„ ZONE ìˆœì„œ ê¸°ë°˜ SEQ ë¶€ì—¬
        cart_zones = self.orders.groupby('CART_NO')['LOC'].apply(lambda locs:
            set(self.rack_to_zone[l] for l in locs if l in self.rack_to_zone)).to_dict()

        cart_order = sorted(cart_zones.keys(), key=lambda c: [
            self.ordered_zone.index(z) for z in cart_zones[c] if z in self.ordered_zone
        ])
        cart_to_seq = {cart: idx+1 for idx, cart in enumerate(cart_order)}

        self.orders['SEQ'] = self.orders['CART_NO'].map(cart_to_seq)
'''

    def solve_picker_routing(self) -> None:
        """Solve Pick Routing Problem (PRP) using simple sequencing"""
        self.orders = self.orders.sort_values(['CART_NO', 'LOC'])
        self.orders['SEQ'] = self.orders.groupby('CART_NO').cumcount() + 1
    

    def solve(self) -> pd.DataFrame:
        """Execute complete warehouse optimization solution"""
        self.solve_storage_location()
        self.solve_order_batching()
        self.solve_picker_routing()
        if self.orders['LOC'].isna().any():
            raise ValueError("LOCì— í• ë‹¹ë˜ì§€ ì•Šì€ SKUê°€ ìˆìŠµë‹ˆë‹¤.")
        if self.orders['CART_NO'].isna().any():
            raise ValueError("CART_NOê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if self.orders['SEQ'].isna().any():
            raise ValueError("SEQê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return self.orders

def main(INPUT: pd.DataFrame, PARAMETER: pd.DataFrame, OD_MATRIX: pd.DataFrame) -> pd.DataFrame:
    solver = WarehouseSolver(INPUT, PARAMETER, OD_MATRIX)
    return solver.solve()

if __name__ == "__main__":
    import time
    test_INPUT = pd.read_csv("./Sample_InputData.csv")
    test_PARAM = pd.read_csv("./Sample_Parameters.csv")
    test_OD = pd.read_csv("Sample_OD_Matrix.csv", index_col=0, header=0)
    start_time = time.time()
    try:
        '''test_INPUT = pd.read_csv("./Sample_InputData.csv")
        test_PARAM = pd.read_csv("./Sample_Parameters.csv")
        test_OD = pd.read_csv("Sample_OD_Matrix.csv", index_col=0, header=0)'''
        print("Data loaded successfully:")
        print(f"- Orders: {test_INPUT.shape}")
        print(f"- Parameters: {test_PARAM.shape}")
        print(f"- OD Matrix: {test_OD.shape}")

        result = main(test_INPUT, test_PARAM, test_OD)
        result.to_csv("Sample_OutputData.csv", index=False)
        print("\nOptimization completed. Results preview:")
        print(result.head())

    except FileNotFoundError as e:
        print(f"Error: Unable to load required files - {str(e)}")
    except (pd.errors.DataError, pd.errors.EmptyDataError) as e:
        print(f"Error: Data validation failed - {str(e)}")
    except Exception as e:
        print(f"Unexpected error: {str(e)}")
    
    print("total_time : ", time.time() - start_time)